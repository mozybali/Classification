"""
NeAR Dataset - BÃ¶brek Anomali Tespiti Projesi
Ana Ã§alÄ±ÅŸtÄ±rma scripti
"""

import argparse
from copy import deepcopy
from pathlib import Path
import sys
import os
import json


def _configure_console() -> None:
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except Exception:
        pass


_configure_console()

# ModÃ¼lleri import et
from src.data_analysis.explore_data import DatasetExplorer
from src.utils.helpers import (
    load_config, 
    save_config, 
    set_seed, 
    get_device,
    count_parameters,
    plot_training_history
)


def show_menu():
    """Ä°nteraktif menÃ¼ gÃ¶ster"""
    os.system('cls' if os.name == 'nt' else 'clear')
    print("="*70)
    print("    NeAR DATASET - BÃ–BREK ANOMALÄ° TESPÄ°TÄ° PROJESÄ°")
    print("    ğŸ¯ Merkezi YÃ¶netim Paneli")
    print("="*70)
    print("\nğŸ“Š VERÄ° ANALÄ°ZÄ° VE KEÅÄ°F:")
    print("  [1] Temel Veri Analizi")
    print("  [2] DetaylÄ± Veri Analizi (Ä°statistiksel Testler)")
    print("  [3] Ã–rnek Veri GÃ¶rÃ¼ntÃ¼le")
    print("  [A] DetaylÄ± Dataset Analizi (tools/analyze_dataset.py)")
    print("\nğŸ–¼ï¸  GÃ–RÃœNTÃœ Ä°ÅLEME:")
    print("  [4] GÃ¶rÃ¼ntÃ¼ Ä°statistikleri Hesapla")
    print("  [5] GÃ¶rÃ¼ntÃ¼ Transform Testleri")
    print("\nğŸ¥ TÄ°BBÄ° GÃ–RÃœNTÃœ Ä°ÅLEME:")
    print("  [M] Medical Transform Testleri")
    print("\nğŸ”§ VERÄ° Ã–NÄ°ÅLEME VE DENGELEME:")
    print("  [6] Temel Veri Ã–n Ä°ÅŸleme")
    print("  [B] Veri Ã–niÅŸleme MenÃ¼sÃ¼ (NaN handling, splitting)")
    print("  [C] SÄ±nÄ±f Dengeleme MenÃ¼sÃ¼ (class balance, augmentation)")
    print("\nğŸ¤– MODEL YÃ–NETÄ°MÄ°:")
    print("  [7] Model EÄŸitimi")
    print("  [8] Model DeÄŸerlendirme")
    print("  [D] Model KarÅŸÄ±laÅŸtÄ±rma ve GÃ¶rselleÅŸtirme")
    print("\nğŸ¯ HÄ°PERPARAMETRE OPTÄ°MÄ°ZASYONU:")
    print("  [H] Hiperparametre Optimizasyonu (Grid/Bayesian Search)")
    print("\nğŸ§ª TEST VE KURULUM:")
    print("  [T] Sistem Test ve Kurulum KontrolÃ¼")
    print("\nâš¡ HIZLI Ä°ÅLEMLER:")
    print("  [9] TÃ¼m Pipeline (Analiz + EÄŸitim)")
    print("\n  [0] Ã‡Ä±kÄ±ÅŸ")
    print("="*70)
    
    choice = input("\nğŸ‘‰ SeÃ§iminizi yapÄ±n: ").strip().upper()
    return choice


def get_menu_action(choice, config):
    """MenÃ¼ seÃ§imine gÃ¶re aksiyon dÃ¶ndÃ¼r"""
    actions = {
        '1': ('analyze', False),
        '2': ('analyze', True),
        '3': ('display', False),
        'A': ('detailed_dataset_analysis', False),
        '4': ('image_stats', False),
        '5': ('transform_test', False),
        'M': ('medical_test', False),
        '6': ('preprocess', False),
        'B': ('preprocessing_menu', False),
        'C': ('class_balance_menu', False),
        '7': ('train', False),
        '8': ('evaluate', False),
        'D': ('model_comparison', False),
        'H': ('hyperparameter_optimization', False),
        'T': ('test_setup', False),
        '9': ('all', True),
        '0': ('exit', False)
    }
    return actions.get(choice, (None, None))


def display_sample_data(config):
    """Ã–rnek verileri gÃ¶rÃ¼ntÃ¼le"""
    import pandas as pd
    
    print("\n" + "="*70)
    print("Ã–RNEK VERÄ° GÃ–RÃœNTÃœLENÄ°YOR")
    print("="*70)
    
    from src.preprocessing.preprocess import resolve_csv_path
    dataset_path = resolve_csv_path(config)
    
    try:
        # Veri setini yÃ¼kle
        df = pd.read_csv(dataset_path)
        
        print(f"\nâœ“ Veri seti yÃ¼klendi: {len(df)} kayÄ±t\n")
        
        # ROI_id'den ek bilgiler Ã§Ä±kar
        df['patient_id'] = df['ROI_id'].str[:5]  # Ä°lk 5 karakter hasta ID
        df['laterality'] = df['ROI_id'].str[-1]  # Son karakter (L/R)
        df['label'] = df['ROI_anomaly'].astype(int)  # Boolean to int
        
        # SÃ¼tun bilgileri
        print("ğŸ“‹ SÃœTUN BÄ°LGÄ°LERÄ°:")
        print("="*70)
        print(f"  â€¢ ROI_id: BÃ¶brek ROI kimliÄŸi (hasta_id + laterality)")
        print(f"  â€¢ subset: Veri seti bÃ¶lÃ¼mÃ¼ (train/test/dev)")
        print(f"  â€¢ ROI_anomaly: Anomali durumu (True/False)")
        print(f"  â€¢ patient_id: Hasta kimliÄŸi (Ã§Ä±karÄ±ldÄ±)")
        print(f"  â€¢ laterality: BÃ¶brek tarafÄ± - L: Sol, R: SaÄŸ (Ã§Ä±karÄ±ldÄ±)")
        print(f"  â€¢ label: Anomali etiketi - 0: Normal, 1: Anomali (Ã§Ä±karÄ±ldÄ±)")
        print()
        
        # Ä°lk 10 kayÄ±t
        print("\nğŸ“Š Ä°LK 10 KAYIT:")
        print("="*70)
        display_df = df[['ROI_id', 'patient_id', 'laterality', 'subset', 'ROI_anomaly', 'label']].head(10)
        print(display_df.to_string(index=True))
        print()
        
        # Anomalili kayÄ±tlar
        anomaly_samples = df[df['ROI_anomaly'] == True][['ROI_id', 'patient_id', 'laterality', 'subset']].head(10)
        print("\nğŸ”´ ANOMALÄ° Ã–RNEK KAYITLAR (Ä°lk 10):")
        print("="*70)
        print(anomaly_samples.to_string(index=True))
        print()
        
        # Normal kayÄ±tlar
        normal_samples = df[df['ROI_anomaly'] == False][['ROI_id', 'patient_id', 'laterality', 'subset']].head(10)
        print("\nğŸŸ¢ NORMAL Ã–RNEK KAYITLAR (Ä°lk 10):")
        print("="*70)
        print(normal_samples.to_string(index=True))
        print()
        
        # Rastgele 5 kayÄ±t
        print("\nğŸ”€ RASTGELE 5 KAYIT:")
        print("="*70)
        random_samples = df[['ROI_id', 'patient_id', 'laterality', 'subset', 'ROI_anomaly']].sample(5, random_state=42)
        print(random_samples.to_string())
        print()
        
        # Temel istatistikler
        print("\nğŸ“ˆ TEMEL Ä°STATÄ°STÄ°KLER:")
        print("="*70)
        
        # Anomali daÄŸÄ±lÄ±mÄ±
        print(f"\nğŸ¯ Anomali DaÄŸÄ±lÄ±mÄ±:")
        anomaly_counts = df['ROI_anomaly'].value_counts()
        print(f"  â€¢ Normal (False): {anomaly_counts.get(False, 0)} (%{anomaly_counts.get(False, 0)/len(df)*100:.2f})")
        print(f"  â€¢ Anomali (True): {anomaly_counts.get(True, 0)} (%{anomaly_counts.get(True, 0)/len(df)*100:.2f})")
        
        # Subset daÄŸÄ±lÄ±mÄ±
        print(f"\nğŸ“¦ Subset DaÄŸÄ±lÄ±mÄ±:")
        for subset, count in df['subset'].value_counts().items():
            anomaly_in_subset = df[(df['subset'] == subset) & (df['ROI_anomaly'] == True)].shape[0]
            print(f"  â€¢ {subset}: {count} ROI ({anomaly_in_subset} anomali, %{anomaly_in_subset/count*100:.2f})")
        
        # Laterality daÄŸÄ±lÄ±mÄ±
        print(f"\nğŸ”„ Laterality DaÄŸÄ±lÄ±mÄ±:")
        for lat, count in df['laterality'].value_counts().items():
            anomaly_in_lat = df[(df['laterality'] == lat) & (df['ROI_anomaly'] == True)].shape[0]
            lat_name = "Sol" if lat == 'L' else "SaÄŸ"
            print(f"  â€¢ {lat_name} ({lat}): {count} ROI ({anomaly_in_lat} anomali, %{anomaly_in_lat/count*100:.2f})")
        
        # Hasta istatistikleri
        print(f"\nğŸ‘¤ Hasta Ä°statistikleri:")
        n_patients = df['patient_id'].nunique()
        print(f"  â€¢ Toplam hasta sayÄ±sÄ±: {n_patients}")
        print(f"  â€¢ Hasta baÅŸÄ±na ortalama ROI: {len(df) / n_patients:.2f}")
        
        # Her iki bÃ¶brekte anomali olan hastalar
        patient_anomaly = df.groupby('patient_id')['ROI_anomaly'].sum()
        both_anomaly = (patient_anomaly == 2).sum()
        one_anomaly = (patient_anomaly == 1).sum()
        no_anomaly = (patient_anomaly == 0).sum()
        print(f"  â€¢ Her iki bÃ¶brek normal: {no_anomaly}")
        print(f"  â€¢ Tek bÃ¶brek anomalili: {one_anomaly}")
        print(f"  â€¢ Her iki bÃ¶brek anomalili: {both_anomaly}")
        
        # Eksik deÄŸer kontrolÃ¼
        print("\n\nğŸ” EKSÄ°K DEÄER KONTROLÃœ:")
        print("="*70)
        missing = df[['ROI_id', 'subset', 'ROI_anomaly']].isnull().sum()
        if missing.sum() > 0:
            print(missing[missing > 0])
        else:
            print("âœ“ Eksik deÄŸer bulunmuyor!")
        
    except Exception as e:
        print(f"\nâŒ Hata: {str(e)}")


def run_medical_transform_test(config):
    """
    Medical transform'larÄ± test et ve sonuÃ§larÄ± gÃ¶ster
    """
    print("\n" + "="*70)
    print("ğŸ¥ TÄ°BBÄ° TRANSFORM TESTLERÄ°")
    print("="*70)
    
    try:
        from src.preprocessing.medical_transforms import (
            MedicalIntensityNormalization,
            AdaptiveROICrop,
            BinaryMaskProcessor,
            get_medical_kidney_pipeline
        )
        import numpy as np
        
        # Synthetic test mask oluÅŸtur
        print("\nğŸ§ª Test mask'i oluÅŸturuluyor...")
        mask = np.zeros((128, 128, 128), dtype=np.float32)
        mask[40:80, 40:80, 40:80] = 1  # Basit kÃ¼p ÅŸeklinde kidney
        
        # Random noise ekle
        noise = np.random.rand(128, 128, 128) < 0.01
        mask[noise] = 1
        
        print(f"  Original: Shape={mask.shape}, Volume={mask.sum():.0f} voxels")
        
        # Test 1: Adaptive ROI Crop
        print("\nğŸ”¬ Test 1: Adaptive ROI Cropping")
        print("  - Non-zero bÃ¶lgeyi otomatik tespit eder")
        print("  - Gereksiz padding'i kaldÄ±rÄ±r (memory optimization)")
        
        crop = AdaptiveROICrop(margin=10, min_size=32)
        cropped = crop(mask)
        
        memory_saved = (1 - cropped.size / mask.size) * 100
        print(f"  Result: Shape={cropped.shape}, Memory saved={memory_saved:.1f}%")
        
        # Test 2: Binary Mask Processing
        print("\nğŸ§¹ Test 2: Binary Mask Post-processing")
        print("  - Noise removal (kÃ¼Ã§Ã¼k component'lar)")
        print("  - Hole filling")
        print("  - Morphological operations")
        
        processor = BinaryMaskProcessor(
            fill_holes=True,
            min_component_size=1000,
            morphology='closing'
        )
        
        cleaned = processor(mask)
        noise_removed = mask.sum() - cleaned.sum()
        print(f"  Result: Noise removed={noise_removed:.0f} voxels")
        
        # Test 3: Medical Intensity Normalization
        print("\nğŸ“Š Test 3: Medical Intensity Normalization")
        print("  - Z-score / Min-max normalization")
        print("  - Percentile-based outlier filtering")
        print("  - Binary mask'ler iÃ§in otomatik skip")
        
        normalizer = MedicalIntensityNormalization(
            method='minmax',
            percentile_range=(1, 99),
            clip_output=True
        )
        
        # Intensity image simÃ¼lasyonu
        intensity_img = np.random.randn(64, 64, 64) * 100 + 500
        normalized = normalizer(intensity_img)
        
        print(f"  Original: Min={intensity_img.min():.1f}, Max={intensity_img.max():.1f}")
        print(f"  Normalized: Min={normalized.min():.2f}, Max={normalized.max():.2f}")
        
        # Test 4: Complete Pipeline
        print("\nğŸ”§ Test 4: Complete Medical Pipeline")
        print("  - ToFloat + AdaptiveCrop + MaskProcessing + Augmentation")
        
        pipeline = get_medical_kidney_pipeline(
            normalize_intensity=False,
            adaptive_crop=True,
            mask_processing=True,
            augmentation=False
        )
        
        processed = pipeline(mask)
        print(f"  Result: {mask.shape} â†’ {processed.shape}")
        print(f"  Volume: {mask.sum():.0f} â†’ {processed.sum():.0f} voxels")
        
        print("\nâœ… TÃ¼m testler baÅŸarÄ±yla tamamlandÄ±!")
        print("\nğŸ’¡ DetaylÄ± bilgi iÃ§in src/preprocessing/test_medical_transforms.py dosyasÄ±nÄ± inceleyebilirsiniz.")
        
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback
        traceback.print_exc()

def analyze_data(config, detailed=False):
    """Veri seti analizi yap"""
    print("\n" + "="*70)
    print("VERÄ° SETÄ° ANALÄ°ZÄ°")
    print("="*70)
    
    from src.preprocessing.preprocess import resolve_csv_path
    dataset_path = resolve_csv_path(config)
    
    if detailed:
        # DetaylÄ± analiz
        from src.data_analysis.detailed_analysis import DetailedAnalyzer
        
        print("\nğŸ” DetaylÄ± analiz modu aktif...")
        analyzer = DetailedAnalyzer(str(dataset_path))
        
        # KapsamlÄ± rapor
        print("\n" + "="*70)
        print("KAPSAMLI RAPOR OLUÅTURULUYOR")
        print("="*70)
        
        # Rapor oluÅŸtur
        plot_dir = Path(config['logging']['plot_dir'])
        plot_dir.mkdir(parents=True, exist_ok=True)
        
        report = analyzer.generate_report(save_path=str(plot_dir.parent / 'detailed_analysis_report.txt'))
        print(report)
        
        # GÃ¶rselleÅŸtirme
        print("\nğŸ“Š KapsamlÄ± gÃ¶rselleÅŸtirmeler oluÅŸturuluyor...")
        analyzer.plot_comprehensive_analysis(save_dir=str(plot_dir))
        
        # Ä°statistikler
        print("\n" + "="*70)
        print("Ä°STATÄ°STÄ°KSEL TESTLER")
        print("="*70)
        
        subset_comp = analyzer.compare_subsets()
        print(f"\nğŸ“Š Subset KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
        print(f"  Chi-Square: {subset_comp['chi_square_test']['chi2']:.4f}")
        print(f"  P-value: {subset_comp['chi_square_test']['p_value']:.4f}")
        print(f"  AnlamlÄ± farklÄ±lÄ±k: {'Evet âœ“' if subset_comp['chi_square_test']['significant'] else 'HayÄ±r âœ—'}")
        
        lat_comp = analyzer.compare_laterality()
        print(f"\nğŸ”„ Laterality KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
        print(f"  Sol anomali oranÄ±: %{lat_comp['anomaly_rates']['left']*100:.2f}")
        print(f"  SaÄŸ anomali oranÄ±: %{lat_comp['anomaly_rates']['right']*100:.2f}")
        print(f"  Fark: %{lat_comp['anomaly_rates']['difference']*100:.2f}")
        
        # Class weights
        weights = analyzer.get_class_weights('balanced')
        print(f"\nâš–ï¸ Ã–nerilen Class Weights:")
        print(f"  Normal (0): {weights['normal']:.4f}")
        print(f"  Anomaly (1): {weights['anomaly']:.4f}")
        print(f"  Ratio: 1:{weights['ratio']:.2f}")
        
        # Ä°lginÃ§ hastalar
        interesting = analyzer.find_interesting_patients()
        print(f"\nğŸ” Ä°lginÃ§ Hasta Profilleri:")
        print(f"  Her iki bÃ¶brek anomalili: {len(interesting['both_anomaly'])} hasta")
        print(f"  Sadece sol anomalili: {len(interesting['left_only'])} hasta")
        print(f"  Sadece saÄŸ anomalili: {len(interesting['right_only'])} hasta")
        
    else:
        # Basit analiz
        explorer = DatasetExplorer(str(dataset_path))
        
        # Analiz ve raporlama
        explorer.print_summary()
        
        # GÃ¶rselleÅŸtirme
        plot_dir = Path(config['logging']['plot_dir'])
        plot_dir.mkdir(parents=True, exist_ok=True)
        explorer.visualize_distribution(save_path=str(plot_dir / 'data_analysis.png'))
        
        print("\nğŸ’¡ Daha detaylÄ± analiz iÃ§in:")
        print("   python main.py --mode analyze --detailed")
        print("   veya tools/analyze_dataset.py'yi kullanabilirsiniz")
    
    print("\nâœ… Veri analizi tamamlandÄ±!")


def preprocess_data(config):
    """Veri Ã¶niÅŸleme"""
    print("\n" + "="*70)
    print("VERÄ° Ã–NÄ°ÅLEME")
    print("="*70)
    
    # Lazy import
    from src.preprocessing.preprocess import DataPreprocessor
    
    # TÃ¼m config'i geÃ§ (DataPreprocessor bunu bekliyor)
    preprocessor = DataPreprocessor(config)
    results = preprocessor.prepare_for_training()
    
    print("\nâœ… Veri Ã¶niÅŸleme tamamlandÄ±!")
    return results

def run_hpo_if_enabled(config, preprocessed_data, device):
    # Run hyperparameter optimization if enabled and return best params
    hpo_cfg = config.get('hpo', {})
    if not hpo_cfg.get('enabled', False):
        return None

    from src.training.hyperparameter_optimizer import HyperparameterOptimizer

    print("\n" + "="*70)
    print("HYPERPARAMETER OPTIMIZATION (AUTO)")
    print("="*70)

    # Build base config for HPO
    hpo_base = deepcopy(config)
    hpo_base.setdefault('training', {})
    hpo_base.setdefault('model', {})

    # Inject class weights into training config (if enabled)
    use_class_weights = (
        config.get('training', {}).get('use_class_weights', True)
        and config.get('class_weights', {}).get('use_in_loss', True)
    )
    if use_class_weights:
        class_weights = (
            preprocessed_data.get('class_weights')
            if config.get('class_weights', {}).get('auto', False)
            else config.get('class_weights', {}).get('manual')
        )
        if class_weights:
            hpo_base['training']['class_weights'] = class_weights
    # Prepare optimizer
    train_loader = preprocessed_data['dataloaders']['train']
    val_loader = preprocessed_data['dataloaders']['dev']
    optimizer = HyperparameterOptimizer(
        base_config=hpo_base,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device
    )

    method = hpo_cfg.get('method', 'bayesian').lower()
    metric = hpo_cfg.get('metric', 'f1')
    num_epochs = int(hpo_cfg.get('num_epochs', 10))

    best_params = None

    if method in ['bayesian', 'optuna']:
        param_distributions = hpo_cfg.get('param_distributions') or {}
        n_trials = int(hpo_cfg.get('n_trials', 30))
        timeout = hpo_cfg.get('timeout')
        n_jobs = int(hpo_cfg.get('n_jobs', 1))
        results = optimizer.bayesian_search(
            param_distributions=param_distributions,
            n_trials=n_trials,
            metric=metric,
            num_epochs=num_epochs,
            timeout=timeout,
            n_jobs=n_jobs
        )
        best_params = results.get('best_params')

    elif method in ['grid', 'grid_search']:
        param_grid = hpo_cfg.get('param_grid') or {}
        results = optimizer.grid_search(
            param_grid=param_grid,
            metric=metric,
            num_epochs=num_epochs,
            save_all_models=False
        )
        best_params = results.get('best_params')

    else:
        print(f"Warning: unknown HPO method '{method}', skipping HPO.")
        return None

    if best_params:
        print("\nBest params from HPO:")
        for k, v in best_params.items():
            print(f"  {k}: {v}")

        # Optionally save best params
        if hpo_cfg.get('save_best_params', True):
            output_dir = Path(hpo_cfg.get('output_dir', 'outputs/hyperparameter_optimization'))
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_dir / 'best_params.json', 'w', encoding='utf-8') as f:
                json.dump(best_params, f, indent=2)

    return best_params



def train_model(config, preprocessed_data=None):
    """Model eÄŸitimi"""
    print("\n" + "="*70)
    print("MODEL EÄÄ°TÄ°MÄ°")
    print("="*70)
    
    # Lazy imports
    from src.models.model_factory import ModelFactory
    from src.training.modular_trainer import ModularTrainer
    
    # Seed ayarla
    set_seed(config['seed'])
    
    # Device seÃ§
    device = get_device(prefer_cuda=(config['device'] == 'cuda'))
    
    # Ã–niÅŸleme (eÄŸer yapÄ±lmamÄ±ÅŸsa)
    if preprocessed_data is None:
        preprocessed_data = preprocess_data(config)

    # Optional HPO before training
    best_params = run_hpo_if_enabled(config, preprocessed_data, device)
    if best_params:
        # Apply best params to config
        for key, value in best_params.items():
            if key in ['learning_rate', 'weight_decay', 'optimizer', 'scheduler', 'momentum']:
                config['training'][key] = value
            elif key in ['batch_size', 'num_workers']:
                config['training'][key] = value
            elif key in ['dropout', 'base_filters', 'model_type']:
                config['model'][key] = value
            else:
                config['training'][key] = value

        # If batch_size/num_workers changed, rebuild dataloaders
        if any(k in best_params for k in ['batch_size', 'num_workers']):
            print("\nRebuilding dataloaders with best batch_size/num_workers...")
            preprocessed_data = preprocess_data(config)
    
    # Model oluÅŸtur
    print("\nğŸ“¦ Model oluÅŸturuluyor...")
    model = ModelFactory.create_model(config['model'])
    model = model.to(device)
    
    # Parametre sayÄ±sÄ±
    count_parameters(model)
    
    # Training config hazirla
    training_config = {
        **config['training'],
        'save_dir': config['training']['save_dir']
    }
    use_class_weights = (
        config.get('training', {}).get('use_class_weights', True)
        and config.get('class_weights', {}).get('use_in_loss', True)
    )
    if use_class_weights:
        training_config['class_weights'] = (
            preprocessed_data.get('class_weights')
            if config.get('class_weights', {}).get('auto', False)
            else config.get('class_weights', {}).get('manual')
        )
    
    # Trainer oluÅŸtur
    trainer = ModularTrainer(
        model=model,
        train_loader=preprocessed_data['dataloaders']['train'],
        val_loader=preprocessed_data['dataloaders']['dev'],
        config=training_config,
        device=device
    )
    
    # EÄŸitimi baÅŸlat
    trainer.train(num_epochs=config['training']['epochs'])
    # Auto evaluation after training (optional)
    run_auto_evaluation(config, preprocessed_data, device, trainer=trainer)

    
    # Training history'yi gÃ¶rselleÅŸtir
    if config['logging']['save_plots']:
        plot_dir = Path(config['logging']['plot_dir'])
        plot_dir.mkdir(parents=True, exist_ok=True)
        plot_training_history(
            trainer.train_losses,
            trainer.val_losses,
            trainer.metrics_history,
            save_path=str(plot_dir / 'training_history.png')
        )
    
    print("\nâœ… Model eÄŸitimi tamamlandÄ±!")
    return trainer

def run_auto_evaluation(config, preprocessed_data, device, trainer=None):
    """Run evaluation automatically after training if enabled."""
    eval_cfg = config.get('evaluation', {})
    if not eval_cfg.get('auto', False):
        return

    test_set = eval_cfg.get('test_set', 'test')
    if test_set in ['val', 'validation']:
        test_set = 'dev'

    # Pick checkpoint
    checkpoint_name = eval_cfg.get('checkpoint_name', 'best_model.pth')
    checkpoint_path = eval_cfg.get('checkpoint_path')
    if checkpoint_path is None:
        checkpoint_path = str(Path(config['training'].get('save_dir', 'checkpoints')) / checkpoint_name)

    # Prepare dataloader
    loaders = preprocessed_data.get('dataloaders') if preprocessed_data else None
    if not loaders or test_set not in loaders:
        try:
            from src.preprocessing.preprocess import DataPreprocessor
            preprocessor = DataPreprocessor(config)
            loaders = preprocessor.get_dataloaders(
                batch_size=config['training'].get('batch_size', 8),
                num_workers=config['training'].get('num_workers', 4)
            )
        except Exception as e:
            print(f"Warning: auto evaluation skipped (dataloader error): {e}")
            return

    test_loader = loaders.get(test_set)
    if test_loader is None:
        print(f"Warning: auto evaluation skipped (test set '{test_set}' not found).")
        return

    from src.training.evaluator import ModelEvaluator
    from src.utils.visualization import create_evaluation_report

    # Load model
    model = None
    if checkpoint_path and Path(checkpoint_path).exists():
        try:
            from src.models.model_factory import load_model_from_checkpoint
            model = load_model_from_checkpoint(checkpoint_path, config['model'], device)
            print(f"Auto evaluation using checkpoint: {checkpoint_path}")
        except Exception as e:
            print(f"Warning: checkpoint load failed, using in-memory model. Error: {e}")
            model = None

    if model is None and trainer is not None:
        model = trainer.model

    if model is None:
        print("Warning: auto evaluation skipped (no model available).")
        return

    save_dir = Path(eval_cfg.get('output_dir', f"outputs/evaluation_{test_set}"))
    evaluator = ModelEvaluator(model, device)

    thr_cfg = eval_cfg.get('threshold', {})
    threshold_strategy = thr_cfg.get('strategy', 'fixed')
    threshold = float(thr_cfg.get('default', 0.5))
    beta = float(thr_cfg.get('beta', 2.0))
    min_precision = thr_cfg.get('min_precision')

    selection_set = thr_cfg.get('selection_set')
    if not selection_set:
        if test_set == 'test' and loaders and 'dev' in loaders:
            selection_set = 'dev'
        else:
            selection_set = test_set
    if selection_set in ['val', 'validation']:
        selection_set = 'dev'
    threshold_loader = loaders.get(selection_set) if loaders else None
    if threshold_loader is None:
        selection_set = None

    results = evaluator.evaluate(
        test_loader,
        save_dir=str(save_dir),
        threshold_strategy=threshold_strategy,
        threshold=threshold,
        beta=beta,
        min_precision=min_precision,
        threshold_loader=threshold_loader,
        threshold_selection=selection_set
    )

    # Report
    try:
        report_path = save_dir / 'evaluation_report.pdf'
        create_evaluation_report(str(save_dir), str(report_path))
        print(f"Auto evaluation report created: {report_path}")
    except Exception as e:
        print(f"Warning: report creation failed: {e}")

    return results



def evaluate_model(config, model_path):
    """Model evaluation"""
    print("\n" + "="*70)
    print("MODEL EVALUATION")
    print("="*70)

    from src.models.model_factory import load_model_from_checkpoint
    from src.preprocessing.preprocess import DataPreprocessor
    from src.training.evaluator import ModelEvaluator
    from src.utils.visualization import create_evaluation_report

    # Model path check
    model_path = model_path.strip()
    if not model_path:
        print("Error: model path is empty.")
        return None

    if not Path(model_path).exists():
        print(f"Error: model file not found: {model_path}")
        return None

    # Device
    device = get_device(prefer_cuda=(config.get('device', 'cuda') == 'cuda'))

    # Test set selection
    test_set = input("\nTest set (test/dev) [test]: ").strip().lower() or 'test'
    if test_set in ['val', 'validation']:
        test_set = 'dev'
    if test_set not in ['test', 'dev']:
        print("Warning: invalid choice, using 'test'.")
        test_set = 'test'

    # Load model
    print("\nLoading model...")
    model = load_model_from_checkpoint(model_path, config['model'], device)

    # Prepare dataloader
    print("\nPreparing test dataloader...")
    preprocessor = DataPreprocessor(config)
    loaders = preprocessor.get_dataloaders(
        batch_size=config['training'].get('batch_size', 8),
        num_workers=config['training'].get('num_workers', 4)
    )

    test_loader = loaders.get(test_set)
    if test_loader is None:
        print(f"Error: test set '{test_set}' not found.")
        return None

    # Evaluate
    save_dir = Path(f"outputs/evaluation_{test_set}")
    evaluator = ModelEvaluator(model, device)

    eval_cfg = config.get('evaluation', {})
    thr_cfg = eval_cfg.get('threshold', {})
    threshold_strategy = thr_cfg.get('strategy', 'fixed')
    threshold = float(thr_cfg.get('default', 0.5))
    beta = float(thr_cfg.get('beta', 2.0))
    min_precision = thr_cfg.get('min_precision')

    selection_set = thr_cfg.get('selection_set')
    if not selection_set:
        if test_set == 'test' and loaders and 'dev' in loaders:
            selection_set = 'dev'
        else:
            selection_set = test_set
    if selection_set in ['val', 'validation']:
        selection_set = 'dev'
    threshold_loader = loaders.get(selection_set) if loaders else None
    if threshold_loader is None:
        selection_set = None

    results = evaluator.evaluate(
        test_loader,
        save_dir=str(save_dir),
        threshold_strategy=threshold_strategy,
        threshold=threshold,
        beta=beta,
        min_precision=min_precision,
        threshold_loader=threshold_loader,
        threshold_selection=selection_set
    )

    # Report
    try:
        report_path = save_dir / 'evaluation_report.pdf'
        create_evaluation_report(str(save_dir), str(report_path))
        print(f"\nReport created: {report_path}")
    except Exception as e:
        print(f"Warning: report creation failed: {e}")

    print("\nModel evaluation completed.")
    return results


def run_hyperparameter_optimization():
    """Run hyperparameter optimization menu"""
    print("\n" + "="*70)
    print("HYPERPARAMETER OPTIMIZATION")
    print("="*70)

    try:
        from cli.run_hyperparameter_optimization import main as hpo_main
        hpo_main()
    except Exception as e:
        print(f"\nError: hyperparameter optimization menu failed: {e}")
        print("\nManual run:")
        print("   python cli/run_hyperparameter_optimization.py")


def run_detailed_dataset_analysis():
    """DetaylÄ± dataset analizi (tools/analyze_dataset.py)"""
    print("\n" + "="*70)
    print("DETAYLI DATASET ANALÄ°ZÄ°")
    print("="*70)
    
    try:
        from tools.analyze_dataset import analyze_samples
        analyze_samples()
    except Exception as e:
        print(f"\nâŒ Analiz Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        print("\nğŸ’¡ Manuel Ã§alÄ±ÅŸtÄ±rma:")
        print("   python tools/analyze_dataset.py")


def run_preprocessing_menu():
    """Veri Ã¶niÅŸleme menÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±r"""
    print("\n" + "="*70)
    print("VERÄ° Ã–NÄ°ÅLEME MENÃœSÃœ")
    print("="*70)
    
    try:
        from cli.data_preprocessing_menu import DataPreprocessingMenu
        menu = DataPreprocessingMenu()
        menu.main()
    except Exception as e:
        print(f"\nâŒ MenÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        print("\nğŸ’¡ Manuel Ã§alÄ±ÅŸtÄ±rma:")
        print("   python cli/data_preprocessing_menu.py")


def run_class_balance_menu():
    """SÄ±nÄ±f dengeleme menÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±r"""
    print("\n" + "="*70)
    print("SINIF DENGELEME MENÃœSÃœ")
    print("="*70)
    
    try:
        from cli.class_balance_menu import ClassBalanceMenu
        menu = ClassBalanceMenu()
        menu.main()
    except Exception as e:
        print(f"\nâŒ MenÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        print("\nğŸ’¡ Manuel Ã§alÄ±ÅŸtÄ±rma:")
        print("   python cli/class_balance_menu.py")


def run_model_comparison():
    """Model karÅŸÄ±laÅŸtÄ±rma gÃ¶rselleÅŸtirmesini Ã§alÄ±ÅŸtÄ±r"""
    print("\n" + "="*70)
    print("MODEL KARÅILAÅTIRMA VE GÃ–RSELLEÅTÄ°RME")
    print("="*70)
    
    try:
        from tools.visualize_model_comparison import main as visualize_main
        visualize_main()
    except Exception as e:
        print(f"\nâŒ GÃ¶rselleÅŸtirme Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        print("\nğŸ’¡ Manuel Ã§alÄ±ÅŸtÄ±rma:")
        print("   python tools/visualize_model_comparison.py")


def run_test_setup():
    """Sistem test ve kurulum kontrolÃ¼"""
    print("\n" + "="*70)
    print("SÄ°STEM TEST VE KURULUM KONTROLÃœ")
    print("="*70)
    
    try:
        from scripts.test_setup import run_all_tests
        run_all_tests()
    except Exception as e:
        print(f"\nâŒ Test Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        print("\nğŸ’¡ Manuel Ã§alÄ±ÅŸtÄ±rma:")
        print("   python scripts/test_setup.py")


def main():
    """Ana fonksiyon"""
    parser = argparse.ArgumentParser(
        description='NeAR Dataset - BÃ¶brek Anomali Tespiti',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
KullanÄ±m Ã–rnekleri:
  Veri analizi:           python main.py --mode analyze
  DetaylÄ± veri analizi:   python main.py --mode analyze --detailed
  Model eÄŸitimi:          python main.py --mode train
  TÃ¼m pipeline:           python main.py --mode all
  
Jupyter Notebook ile detaylÄ± inceleme:
  jupyter notebook notebooks/01_data_exploration.ipynb
        """
    )
    
    parser.add_argument('--config', type=str, default='configs/config.yaml',
                        help='Config dosyasÄ± yolu')
    parser.add_argument('--mode', type=str, default=None,
                        choices=['analyze', 'preprocess', 'train', 'evaluate', 'all'],
                        help='Ã‡alÄ±ÅŸtÄ±rma modu (belirtilmezse menÃ¼ gÃ¶sterilir)')
    parser.add_argument('--detailed', action='store_true',
                        help='DetaylÄ± analiz modu (sadece analyze ile kullanÄ±lÄ±r)')
    parser.add_argument('--model-path', type=str, default=None,
                        help='DeÄŸerlendirme iÃ§in model yolu')
    
    args = parser.parse_args()
    
    # Config yÃ¼kle
    print(f"\nğŸ“„ Config yÃ¼kleniyor: {args.config}")
    config = load_config(args.config)
    
    # EÄŸer mode belirtilmemiÅŸse menÃ¼ gÃ¶ster
    if args.mode is None:
        while True:
            choice = show_menu()
            
            if choice == '0':
                print("\nğŸ‘‹ Ã‡Ä±kÄ±lÄ±yor...\n")
                break
            
            action, detailed = get_menu_action(choice, config)
            
            if action is None:
                print("\nâŒ GeÃ§ersiz seÃ§im! LÃ¼tfen 0-9 arasÄ± bir sayÄ± girin.")
                input("\nDevam etmek iÃ§in Enter'a basÄ±n...")
                continue
            
            # SeÃ§ime gÃ¶re iÅŸlemi Ã§alÄ±ÅŸtÄ±r
            try:
                if action == 'analyze':
                    analyze_data(config, detailed=detailed)
                elif action == 'display':
                    display_sample_data(config)
                elif action == 'detailed_dataset_analysis':
                    run_detailed_dataset_analysis()
                elif action == 'image_stats':
                    from src.utils.image_processing_utils import compute_image_statistics
                    compute_image_statistics(config)
                elif action == 'transform_test':
                    from src.utils.image_processing_utils import test_image_transforms
                    test_image_transforms(config)
                elif action == 'medical_test':
                    run_medical_transform_test(config)
                elif action == 'preprocess':
                    preprocess_data(config)
                elif action == 'preprocessing_menu':
                    run_preprocessing_menu()
                elif action == 'class_balance_menu':
                    run_class_balance_menu()
                elif action == 'train':
                    preprocessed_data = preprocess_data(config)
                    train_model(config, preprocessed_data)
                elif action == 'evaluate':
                    model_path = input("\nğŸ“‚ Model dosyasÄ± yolu: ").strip()
                    if not model_path:
                        print("âŒ Model yolu belirtilmedi!")
                    else:
                        evaluate_model(config, model_path)
                elif action == 'model_comparison':
                    run_model_comparison()
                elif action == 'hyperparameter_optimization':
                    run_hyperparameter_optimization()
                elif action == 'test_setup':
                    run_test_setup()
                elif action == 'all':
                    analyze_data(config, detailed=True)
                    preprocessed_data = preprocess_data(config)
                    train_model(config, preprocessed_data)
                
                print("\n" + "="*70)
                print("âœ… Ä°ÅLEM TAMAMLANDI")
                print("="*70)
                input("\nDevam etmek iÃ§in Enter'a basÄ±n...")
                
            except KeyboardInterrupt:
                print("\n\nâš ï¸  Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan iptal edildi.")
                input("\nDevam etmek iÃ§in Enter'a basÄ±n...")
            except Exception as e:
                print(f"\nâŒ Hata oluÅŸtu: {str(e)}")
                input("\nDevam etmek iÃ§in Enter'a basÄ±n...")
        
        return
    
    # Komut satÄ±rÄ± argÃ¼manÄ± ile Ã§alÄ±ÅŸtÄ±rma (eski davranÄ±ÅŸ)
    if args.mode == 'analyze':
        analyze_data(config, detailed=args.detailed)
    
    elif args.mode == 'preprocess':
        preprocess_data(config)
    
    elif args.mode == 'train':
        preprocessed_data = preprocess_data(config)
        train_model(config, preprocessed_data)
    
    elif args.mode == 'evaluate':
        if args.model_path is None:
            print("âŒ --model-path argÃ¼manÄ± gerekli!")
            sys.exit(1)
        evaluate_model(config, args.model_path)
    
    elif args.mode == 'all':
        # TÃ¼m pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
        analyze_data(config, detailed=True)
        preprocessed_data = preprocess_data(config)
        train_model(config, preprocessed_data)
    
    print("\n" + "="*70)
    print("âœ… Ä°ÅLEM TAMAMLANDI")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
